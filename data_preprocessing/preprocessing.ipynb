{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing \n",
    "### Input Folder structure:\n",
    "\n",
    "```\n",
    "data\n",
    "|   ├── icesat_data\n",
    "|       - download_icesat.sh\n",
    "|   ├── boreal_agb_density_ICESat2_tiles_shp\n",
    "    |       - Boreal_AGB_Density_ICESat2_tiles.dbf\n",
    "    |       - Boreal_AGB_Density_ICESat2_tiles.prj\n",
    "    |       - Boreal_AGB_Density_ICESat2_tiles.sbn\n",
    "    |       - Boreal_AGB_Density_ICESat2_tiles.sbx\n",
    "    |       - Boreal_AGB_Density_ICESat2_tiles.shp\n",
    "    |       - Boreal_AGB_Density_ICESat2_tiles.shx\n",
    "    ├── S2_tiles_Siberia_polybox\n",
    "    |   - S2_tiles_Siberia_above_GEDI.geojson\n",
    "    |   - S2_tiles_Siberia_all.geojson\n",
    "    |   - S2_tiles_Siberia_within_GEDI.geojson\n",
    "preprocessing\n",
    "    - preprocessing.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import rasterio as rs\n",
    "from rasterio.merge import merge\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.mask import mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finding the corresponding IceSat-2 tiles for every Sentinel-2 tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in Sentinel 2 shapefile\n",
    "s2_df = gpd.read_file('../data/S2_tiles_Siberia_polybox/S2_tiles_Siberia_all.geojson', driver='GeoJSON', index = False) \n",
    "# print(s2_df.head())\n",
    "#reading in ICESat2 shapefile\n",
    "icesat_df = gpd.read_file('../data/boreal_agb_density_ICESat2_tiles_shp/Boreal_AGB_Density_ICESat2_tiles.shp', driver='ESRI Shapefile', index = False)\n",
    "# print(icesat_df.head())\n",
    "        \n",
    "overlapping_tiles = pd.DataFrame()\n",
    "#iterating over each Sentinel 2 tile and finding the ICESat2 tiles that overlap with it\n",
    "for _, s2_tile in s2_df.iterrows():\n",
    "    s2_geometry = s2_tile.geometry\n",
    "    overlapping_icesat_tiles = icesat_df[icesat_df.geometry.intersects(s2_geometry)].copy()\n",
    "\n",
    "    # adding the name of the S2 tile to the ICESat2 tiles that overlap with it\n",
    "    if not overlapping_icesat_tiles.empty:\n",
    "        overlapping_icesat_tiles.loc[:, 'S2 Tile Name'] = s2_tile.Name\n",
    "        # overlapping_icesat_tiles.loc[:, 'S2 Tile Geometry'] = s2_geometry\n",
    "    \n",
    "    overlapping_tiles = pd.concat([overlapping_tiles, overlapping_icesat_tiles])\n",
    "\n",
    "# overlapping_tiles_df = gpd.GeoDataFrame(overlapping_tiles, columns=['S2 Tile Name', 'Overlapping ICESat Tiles'])\n",
    "overlapping_tiles.to_csv('overlapping_tiles.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparing to download, create a 'links.txt' file which contains the download links of the relevant IceSat-2 granules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'overlapping_tiles.csv'\n",
    "\n",
    "# Get the column index of \"GeoTiff\"\n",
    "geo_tiff_column_index = overlapping_tiles.columns.get_loc(\"GeoTIFF\")\n",
    "\n",
    "filenames = []\n",
    "\n",
    "with open(csv_file, 'r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    next(csv_reader)  # Skip the header row\n",
    "\n",
    "    for row in csv_reader:\n",
    "        if row[geo_tiff_column_index] not in filenames:\n",
    "            filenames.append(row[geo_tiff_column_index])\n",
    "\n",
    "# print(filenames)\n",
    "\n",
    "with open('links.txt', 'w') as file:\n",
    "    for filename in filenames:\n",
    "        file.write('https://data.ornldaac.earthdata.nasa.gov/protected/above/Boreal_AGB_Density_ICESat2/data/' + filename + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 'download_icesat.sh' \n",
    "The script should be located in the 'data/icesat_data' folder. Replace 'username' and 'password' with your ***correct*** earthdata credentials\n",
    "\n",
    "Open a terminal in the 'data/icesat_data' folder and run:\n",
    "\n",
    "\\>\\> chmod 777 download_icesat.sh\n",
    "\n",
    "\\>\\> ./download_icesat.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Mosaic the tiles together\n",
    "\n",
    "This will create a \"/merged_mosaic\" folder where for every Sentinel-2 tile we save the overlapping IceSat-2 tiles mosaiced together as [S2-tilename]_mosaic.tif These mosaiced tiles are still in the IceSat-2 crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the CSV file\n",
    "if 'csv_file' not in globals():\n",
    "    csv_file = 'overlapping_tiles.csv'\n",
    "if 'df' not in globals():\n",
    "    # Read the CSV file as a DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "if 'unique_tiles' not in globals():\n",
    "    # Get the unique values in the \"S2 Tile Name\" column\n",
    "    unique_tiles = df['S2 Tile Name'].unique()\n",
    "if 's2_df' not in globals():\n",
    "    s2_df = gpd.read_file('../data/S2_tiles_Siberia_polybox/S2_tiles_Siberia_all.geojson', driver='GeoJSON', index = False)\n",
    "\n",
    "\n",
    "# Iterate over the unique tiles\n",
    "for tile in unique_tiles:\n",
    "    print(f'Processing tile {tile}...')\n",
    "    entry = s2_df[s2_df['Name']==tile]\n",
    "    icesat_tiles = []\n",
    "    for index, row in df[df['S2 Tile Name']==tile].iterrows():\n",
    "        icesat_tiles.append(row['GeoTIFF'])\n",
    "    \n",
    "    to_merge = []\n",
    "    # Construct the path to the corresponding tif file\n",
    "    for icesat_tile in icesat_tiles:\n",
    "        temp_tiff = rs.open(f'../data/icesat_data/{icesat_tile}')\n",
    "        to_merge.append(temp_tiff)\n",
    "    \n",
    "    assert len(to_merge)!=0, \"No corresponding ICESat-2 tiles found\"\n",
    "    # Check if the CRS of all the to_merge are the same\n",
    "    crs_check = all(to_merge[0].crs == t.crs for t in to_merge)\n",
    "    if not crs_check:\n",
    "        raise ValueError(\"CRS of the to_merge tiles are not the same\")\n",
    "  \n",
    "    # Merge the tiles\n",
    "    mosaic, mosaic_trans = merge(to_merge)\n",
    "    mosaic_crs = to_merge[0].crs\n",
    "\n",
    "    height, width = mosaic.shape[1], mosaic.shape[2]\n",
    "    output_meta = to_merge[0].meta.copy()\n",
    "    output_meta.update({\"driver\": \"GTiff\",\n",
    "                        \"height\": height,\n",
    "                        \"width\": width,\n",
    "                        \"transform\": mosaic_trans,\n",
    "                        \"count\": mosaic.shape[0]})\n",
    "    output_path = f'merged_mosaic/{tile}_mosaic.tif'\n",
    "\n",
    "    # Specify the path to the merged_mosaic folder\n",
    "    merged_mosaic_folder = 'merged_mosaic'\n",
    "\n",
    "    # Check if the merged_mosaic folder exists\n",
    "    if not os.path.exists(merged_mosaic_folder):\n",
    "        # Create the merged_mosaic folder\n",
    "        os.makedirs(merged_mosaic_folder)\n",
    "    \n",
    "    with rs.open(output_path, \"w\", **output_meta) as dest:\n",
    "        dest.write(mosaic)\n",
    "\n",
    "\n",
    "    # Close the tiles' files\n",
    "    for src in to_merge : src.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reprojecting the mosaics\n",
    "\n",
    "We reproject the mosaics from the IceSat-2 crs to the Sentinel-2 crs and save them to the \"/reprojected_mosaic\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a helper function to get the CRS of the Sentinel-2 tile from its name\n",
    "# it is used in both reprojecting and cropping the tiles\n",
    "def get_CRS_from_S2_tilename(tname) :\n",
    "    \"\"\"\n",
    "    Get the CRS of the Sentinel-2 tile from its name. The tiles are named as DDCCC (where D is a digit and C a character).\n",
    "    MGRS tiles are in UTM projection, which means the CRS will be EPSG=326xx in the Northern Hemisphere, and 327xx in the\n",
    "    Southern. The first character of the tile name gives you the hemisphere (C to M is South, N to X is North); and the\n",
    "    two digits give you the UTM zone number.\n",
    "\n",
    "    Args:\n",
    "    - tname: str, name of the Sentinel-2 tile\n",
    "\n",
    "    Returns:\n",
    "    - rasterio.crs.CRS, the CRS of the Sentinel-2 tile\n",
    "    \"\"\"\n",
    "\n",
    "    tile_code, hemisphere = tname[:2], tname[2]\n",
    "\n",
    "    if 'C' <= hemisphere <= 'M':\n",
    "        crs = f'EPSG:327{tile_code}'\n",
    "    elif 'N' <= hemisphere <= 'X':\n",
    "        crs = f'EPSG:326{tile_code}'\n",
    "    else:\n",
    "        raise ValueError(f'Invalid hemisphere code: {hemisphere}')\n",
    "    \n",
    "    return rs.crs.CRS.from_string(crs)\n",
    "\n",
    "# Open the original raster dataset\n",
    "def custom_reproject(src_path, output_path, dst_crs):\n",
    "    # Open the original raster dataset\n",
    "    with rs.open(src_path) as src:\n",
    "        \n",
    "        # Calculate the transformation parameters and the width and height of the output\n",
    "        # in the new CRS\n",
    "        transform, width, height = calculate_default_transform(\n",
    "            src.crs, dst_crs, src.width, src.height, *src.bounds)\n",
    "        \n",
    "        # Copy the metadata from the source dataset\n",
    "        kwargs = src.meta.copy()\n",
    "        # Update the metadata with the new CRS, transformation, and dimensions\n",
    "        kwargs.update({\n",
    "            'crs': dst_crs,\n",
    "            'transform': transform,\n",
    "            'width': width,\n",
    "            'height': height\n",
    "        })\n",
    "\n",
    "        # Specify the path to the merged_mosaic folder\n",
    "        reprojected_mosaic_folder = 'reprojected_mosaic'\n",
    "\n",
    "        # Check if the merged_mosaic folder exists\n",
    "        if not os.path.exists(reprojected_mosaic_folder):\n",
    "            # Create the merged_mosaic folder\n",
    "            os.makedirs(reprojected_mosaic_folder)\n",
    "\n",
    "        # Open a new raster file for the reprojected data\n",
    "        with rs.open(output_path, 'w', **kwargs) as dst:\n",
    "            \n",
    "            # Reproject each band in the raster dataset\n",
    "            for i in range(1, src.count + 1):\n",
    "                reproject(\n",
    "                    # Source raster band\n",
    "                    source=rs.band(src, i),\n",
    "                    # Destination raster band\n",
    "                    destination=rs.band(dst, i),\n",
    "                    # Source transformation and CRS\n",
    "                    src_transform=src.transform,\n",
    "                    src_crs=src.crs,\n",
    "                    # Destination transformation and CRS\n",
    "                    dst_transform=transform,\n",
    "                    dst_crs=dst_crs,\n",
    "                    # Resampling method\n",
    "                    resampling=Resampling.nearest)\n",
    "\n",
    "\n",
    "# Specify the path to the CSV file\n",
    "if 'csv_file' not in globals():\n",
    "    csv_file = 'overlapping_tiles.csv'\n",
    "if 'df' not in globals():\n",
    "    # Read the CSV file as a DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "if 'unique_tiles' not in globals():\n",
    "    # Get the unique values in the \"S2 Tile Name\" column\n",
    "    unique_tiles = df['S2 Tile Name'].unique()\n",
    "if 's2_df' not in globals():\n",
    "    s2_df = gpd.read_file('../data/S2_tiles_Siberia_polybox/S2_tiles_Siberia_all.geojson', driver='GeoJSON', index = False)\n",
    "\n",
    "    \n",
    "# Iterate over the unique tiles\n",
    "for tile in unique_tiles:\n",
    "    print(f'Processing tile {tile}...')\n",
    "    entry = s2_df[s2_df['Name']==tile]\n",
    "\n",
    "    dest_crs = get_CRS_from_S2_tilename(tile)\n",
    "\n",
    "    # Read in the (tile)_mosaic.tif file\n",
    "    mosaic_file = f'merged_mosaic/{tile}_mosaic.tif'\n",
    "    custom_reproject(mosaic_file, f'reprojected_mosaic/{tile}_reprojected_mosaic.tif', dest_crs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cropping the reprojected mosaics\n",
    "We crop the reprojected mosaics to the corresponding Sentinel-2 tile and save them to the \"/cropped_mosaic\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the CSV file\n",
    "if 'csv_file' not in globals():\n",
    "    csv_file = 'overlapping_tiles.csv'\n",
    "if 'df' not in globals():\n",
    "    # Read the CSV file as a DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "if 'unique_tiles' not in globals():\n",
    "    # Get the unique values in the \"S2 Tile Name\" column\n",
    "    unique_tiles = df['S2 Tile Name'].unique()\n",
    "if 's2_df' not in globals():\n",
    "    s2_df = gpd.read_file('../data/S2_tiles_Siberia_polybox/S2_tiles_Siberia_all.geojson', driver='GeoJSON', index = False)\n",
    "\n",
    "# Specify the directory path\n",
    "directory = 'reprojected_mosaic'\n",
    "\n",
    "# Iterate over the unique tiles\n",
    "for tile in unique_tiles:\n",
    "    print(f'Processing tile {tile}...')\n",
    "    # Get the file paths of all the files in the directory\n",
    "    file_path = os.path.join(directory, tile + \"_reprojected_mosaic.tif\")\n",
    "    entry = s2_df[s2_df['Name']==tile]\n",
    "\n",
    "    \n",
    "    #reproject the tiles to the same CRS\n",
    "    dest_crs = get_CRS_from_S2_tilename(tile)\n",
    "    # print(\"entry.crs:  \" + str(entry.crs))\n",
    "    reprojected_entry = entry.to_crs(dest_crs, inplace=False)\n",
    "    # print(reprojected_entry.crs.to_epsg())\n",
    "\n",
    "    # Specify the path to the merged_mosaic folder\n",
    "    cropped_mosaic_folder = 'cropped_mosaic'\n",
    "\n",
    "    # Check if the merged_mosaic folder exists\n",
    "    if not os.path.exists(cropped_mosaic_folder):\n",
    "        # Create the merged_mosaic folder\n",
    "        os.makedirs(cropped_mosaic_folder)\n",
    "\n",
    "\n",
    "    with rs.open(file_path) as dataset:\n",
    "        # Access the data or perform any required operations\n",
    "        data = dataset.read()\n",
    "        # Do something with the data\n",
    "        out_image, out_transform = mask(dataset, reprojected_entry.geometry, crop=True)\n",
    "        out_meta = dataset.meta.copy()\n",
    "        out_meta.update({\"driver\": \"GTiff\",\n",
    "                         \"height\": out_image.shape[1],\n",
    "                         \"width\": out_image.shape[2],\n",
    "                         \"transform\": out_transform})\n",
    "        output_path = f'cropped_mosaic/{tile}_cropped_mosaic.tif'   \n",
    "        with rs.open(output_path, \"w\", **out_meta) as dest:\n",
    "            dest.write(out_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output\n",
    "After running the above code we should now have the following folder structure:\n",
    "\n",
    "```\n",
    "data\n",
    "    ├── icesat_data\n",
    "        - download_icesat.sh\n",
    "    ├── boreal_agb_density_ICESat2_tiles_shp\n",
    "    |       - Boreal_AGB_Density_ICESat2_tiles.dbf\n",
    "    |       - Boreal_AGB_Density_ICESat2_tiles.prj\n",
    "    |       - Boreal_AGB_Density_ICESat2_tiles.sbn\n",
    "    |       - Boreal_AGB_Density_ICESat2_tiles.sbx\n",
    "    |       - Boreal_AGB_Density_ICESat2_tiles.shp\n",
    "    |       - Boreal_AGB_Density_ICESat2_tiles.shx\n",
    "    ├── S2_tiles_Siberia_polybox\n",
    "    |   - S2_tiles_Siberia_above_GEDI.geojson\n",
    "    |   - S2_tiles_Siberia_all.geojson\n",
    "    |   - S2_tiles_Siberia_within_GEDI.geojson\n",
    "preprocessing\n",
    "    ├── cropped_mosaic\n",
    "    ├── merged_mosaic\n",
    "    └── reprojected_mosaic\n",
    "    - links.txt\n",
    "    - overlapping_tiles.csv\n",
    "    - preprocessing.ipynb\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
